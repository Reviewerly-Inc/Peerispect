{
  "submission_id": "qjnl1QUnFA",
  "submission_title": "High-Fidelity Audio Compression with Improved RVQGAN",
  "review_index": 2,
  "review_id": "YjQqdH8Z78",
  "reviewer": "Reviewer_ZhX4",
  "invitation": "NeurIPS.cc/2023/Conference/Submission14752/-/Official_Review",
  "invitations": [
    "NeurIPS.cc/2023/Conference/Submission14752/-/Official_Review",
    "NeurIPS.cc/2023/Conference/-/Edit"
  ],
  "signatures": [
    "NeurIPS.cc/2023/Conference/Submission14752/Reviewer_ZhX4"
  ],
  "rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
  "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
  "review_text": "",
  "summary": "This paper introduces a novel high-fidelity neural audio compression algorithm that achieves impressive compression ratios while maintaining audio quality. The authors combine advancements in high-fidelity audio generation with improved vector quantization techniques from the image domain, along with enhanced adversarial and reconstruction losses. Their approach achieves a remarkable 90x compression of 44.1 KHz audio into tokens at just 8kbps bandwidth. One of the notable strengths of this work is its universal applicability, as it can compress various audio domains (speech, environment, music) using a single model.\n\nThe authors conduct a thorough comparison with competing audio compression algorithms and demonstrate the superior performance of their method. Furthermore, they provide detailed ablations for each design choice, allowing readers to gain insights into the effectiveness of different components. Additionally, the paper offers open-source code and trained model weights, which contribute to the reproducibility of the results.",
  "strengths": "- **Impressive compression performance**: The proposed algorithm achieves a 90x compression ratio for 44.1 KHz audio at just 8kbps bandwidth, demonstrating its effectiveness in reducing data size while preserving audio quality.\n- **Novel Method**: The proposed \"codebook collapse\" and \"quantizer dropout\" effectively address the issues in lossy audio compression. \n- **Universal applicability**: The single model's ability to compress various audio domains makes it highly versatile and applicable to generative modeling of different audio types.\n- **Comprehensive evaluation**: The authors compare their method against existing audio compression algorithms, demonstrating its superiority in terms of performance.\n- **Thorough ablations**: The paper provides detailed insights into the impact of design choices, allowing readers to understand the effectiveness of different components and their contributions to the overall results.\n- **Reproducibility**: The availability of open-source code and trained model weights enhances the reproducibility of the research, enabling other researchers to build upon and validate the findings.",
  "weaknesses": "- The novelty of the proposed model structure is a combination of existing models: \n  - factorized codes and L2-normalized codes are from Improved VQGAN image model;\n  - Snake activation function from BigVGAN\n- This paper presents a strong audio compression technique. However, since the proposed novel points are specifically tailored for a narrow domain, their impact may be limited to the machine learning community and other domains like computer vision/NLP",
  "questions": "- Have you attempted to apply a similar architecture to the vocoder in TTS? \n- Which components do you believe can be applied and generalized to other domains or tasks?",
  "limitations": "The authors have adequately addressed the limitations.",
  "soundness": "3 good",
  "presentation": "3 good",
  "contribution": "3 good",
  "flag_for_ethics_review": [
    "No ethics review needed."
  ],
  "details_of_ethics_concerns": "",
  "combined_review_text": "This paper introduces a novel high-fidelity neural audio compression algorithm that achieves impressive compression ratios while maintaining audio quality. The authors combine advancements in high-fidelity audio generation with improved vector quantization techniques from the image domain, along with enhanced adversarial and reconstruction losses. Their approach achieves a remarkable 90x compression of 44.1 KHz audio into tokens at just 8kbps bandwidth. One of the notable strengths of this work is its universal applicability, as it can compress various audio domains (speech, environment, music) using a single model.\n\nThe authors conduct a thorough comparison with competing audio compression algorithms and demonstrate the superior performance of their method. Furthermore, they provide detailed ablations for each design choice, allowing readers to gain insights into the effectiveness of different components. Additionally, the paper offers open-source code and trained model weights, which contribute to the reproducibility of the results.\n3 good\n3 good\n3 good\n- **Impressive compression performance**: The proposed algorithm achieves a 90x compression ratio for 44.1 KHz audio at just 8kbps bandwidth, demonstrating its effectiveness in reducing data size while preserving audio quality.\n- **Novel Method**: The proposed \"codebook collapse\" and \"quantizer dropout\" effectively address the issues in lossy audio compression. \n- **Universal applicability**: The single model's ability to compress various audio domains makes it highly versatile and applicable to generative modeling of different audio types.\n- **Comprehensive evaluation**: The authors compare their method against existing audio compression algorithms, demonstrating its superiority in terms of performance.\n- **Thorough ablations**: The paper provides detailed insights into the impact of design choices, allowing readers to understand the effectiveness of different components and their contributions to the overall results.\n- **Reproducibility**: The availability of open-source code and trained model weights enhances the reproducibility of the research, enabling other researchers to build upon and validate the findings.\n- The novelty of the proposed model structure is a combination of existing models: \n  - factorized codes and L2-normalized codes are from Improved VQGAN image model;\n  - Snake activation function from BigVGAN\n- This paper presents a strong audio compression technique. However, since the proposed novel points are specifically tailored for a narrow domain, their impact may be limited to the machine learning community and other domains like computer vision/NLP\n- Have you attempted to apply a similar architecture to the vocoder in TTS? \n- Which components do you believe can be applied and generalized to other domains or tasks?\nThe authors have adequately addressed the limitations.\n7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nYes"
}